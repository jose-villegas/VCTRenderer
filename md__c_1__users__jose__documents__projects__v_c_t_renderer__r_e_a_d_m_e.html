<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.18"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VCT Engine: Deferred Voxel Shading for Real Time Global Illumination</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">VCT Engine
   </div>
   <div id="projectbrief">Rendering engine using voxel cone tracing for global illumination.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.18 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md__c_1__users__jose__documents__projects__v_c_t_renderer__r_e_a_d_m_e.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Deferred Voxel Shading for Real Time Global Illumination </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md1"></a>
Table of Contents</h1>
<ul>
<li><a href="#overview">Overview</a><ul>
<li><a href="#1-voxelization">1. Voxelization</a><ul>
<li><a href="#11-voxel-structure">1.1. Voxel Structure</a></li>
<li><a href="#12-dynamic-voxelization">1.2. Dynamic Voxelization</a></li>
</ul>
</li>
<li><a href="#2-voxel-illumination">2. Voxel Illumination</a><ul>
<li><a href="#21-normal-weighted-attenuation">2.1. Normal-Weighted Attenuation</a></li>
<li><a href="#22-voxel-occlusion">2.2. Voxel Occlusion</a><ul>
<li><a href="#221-soft-voxel-shadows">2.2.1. Soft Voxel Shadows</a></li>
</ul>
</li>
<li><a href="#23-emission">2.3. Emission</a></li>
</ul>
</li>
<li><a href="#3-anisotropic-voxels">3. Anisotropic Voxels</a></li>
<li><a href="#4-voxel-cone-tracing">4. Voxel Cone Tracing</a><ul>
<li><a href="#41-indirect-illumination">4.1. Indirect Illumination</a></li>
<li><a href="#42-ambient-occlusion">4.2. Ambient Occlusion</a></li>
<li><a href="#43-soft-shadows">4.3. Soft Shadows</a></li>
</ul>
</li>
<li><a href="#voxel-global-illumination">Voxel Global Illumination</a></li>
</ul>
</li>
<li><a href="#results">Results</a><ul>
<li><a href="#voxelization">Voxelization</a></li>
<li><a href="#voxel-illumination">Voxel Illumination</a></li>
<li><a href="#voxel-cone-tracing">Voxel Cone Tracing</a></li>
<li><a href="#comparison">Comparison</a><ul>
<li><a href="#optimizations">Optimizations</a></li>
</ul>
</li>
<li><a href="#show-off">Show Off</a><ul>
<li><a href="#dynamic-update">Dynamic Update</a></li>
<li><a href="#indirect-lighting">Indirect Lighting</a></li>
<li><a href="#ambient-occlusion">Ambient Occlusion</a></li>
<li><a href="#soft-shadows">Soft Shadows</a></li>
<li><a href="#emissive-materials--area-lights">Emissive Materials / Area Lights</a></li>
<li><a href="#teasers">Teasers</a></li>
<li><a href="#recording">Recording</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#executable">Executable</a></li>
</ul>
<p><em>Peer-review published paper for this technique can be found here:</em> <a href="http://ieeexplore.ieee.org/abstract/document/7833375/">http://ieeexplore.ieee.org/abstract/document/7833375/</a></p>
<p>My thesis can be found here (Spanish) here: <a href="https://raw.githubusercontent.com/jose-villegas/ThesisDocument/master/Tesis.pdf">https://raw.githubusercontent.com/jose-villegas/ThesisDocument/master/Tesis.pdf</a></p>
<p>Computing indirect illumination is a challenging and complex problem for real-time rendering in 3D applications. This global illumination approach computes indirect lighting in real time utilizing a simpliﬁed version of the outgoing radiance and the scene stored in voxels.</p>
<h1><a class="anchor" id="autotoc_md2"></a>
Overview</h1>
<p>Deferred voxel shading is a four-step real-time global illumination technique inspired by voxel cone tracing and deferred rendering. This approach enables us to obtain an accurate approximation of a plethora of indirect illumination effects including: indirect diffuse, specular reflectance, color-blending, emissive materials, indirect shadows and ambient occlusion. The steps that comprehend this technique are described below.</p>
<table class="doxtable">
<tr>
<th>Technique Overview  </th></tr>
<tr>
<td align="center"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497489937/dvsgi_overview_vlucdk.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md3"></a>
1. Voxelization</h2>
<p>The first step is to voxelize the scene, my implemention voxelizes scene albedo, normal and emission to approximate emissive materials. For this conservative voxelization and atomic operations on 3D textures are used as described <a href="https://www.seas.upenn.edu/~pcozzi/OpenGLInsights/OpenGLInsights-SparseVoxelization.pdf">here</a>.</p>
<div class="fragment"><div class="line">...</div>
<div class="line">layout(binding = 0, r32ui) uniform <span class="keyword">volatile</span> coherent uimage3D voxelAlbedo;</div>
<div class="line">layout(binding = 1, r32ui) uniform <span class="keyword">volatile</span> coherent uimage3D voxelNormal;</div>
<div class="line">layout(binding = 2, r32ui) uniform <span class="keyword">volatile</span> coherent uimage3D voxelEmission;</div>
<div class="line">...</div>
<div class="line"><span class="comment">// average normal per fragments sorrounding the voxel volume</span></div>
<div class="line">imageAtomicRGBA8Avg(voxelNormal, position, normal);</div>
<div class="line"><span class="comment">// average albedo per fragments sorrounding the voxel volume</span></div>
<div class="line">imageAtomicRGBA8Avg(voxelAlbedo, position, albedo);</div>
<div class="line"><span class="comment">// average emission per fragments sorrounding the voxel volume</span></div>
<div class="line">imageAtomicRGBA8Avg(voxelEmission, position, emissive);</div>
<div class="line">...</div>
</div><!-- fragment --><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><a class="el" href="class_scene.html" title="Represents a scene composed of many cameras, meshes, lights, textures and materials....">Scene</a> </th><th class="markdownTableHeadNone">Average Albedo </th><th class="markdownTableHeadNone">Average Normal </th><th class="markdownTableHeadNone">Average Emission  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323827/DVSGI/scene_culelk.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323820/DVSGI/v_albedo_qtc4ov.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323804/DVSGI/v_normal_ryzmrh.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323828/DVSGI/v_emission_aibyaf.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md4"></a>
1.1. Voxel Structure</h3>
<p>My voxel structure is inspired by deferred rendering, where a G-Buffer contains relevant data to later be used in a separate light pass. Normal, albedo and emission values are stored in voxels during the voxelization process, every attribute has its own 3D texture associated. This information is sufficient to calculate the diffuse reflectance and normal attenuation on a separate light pass where, instead of computing the lighting per pixel it is done per voxel. The structure can be extended to support a more complicated reflectance model but this may imply a higher memory consumption to store additional data.</p>
<p>Furthermore, another structure is used for the voxel cone tracing pass. The resulting values of the lighting computations per voxel are stored in another 3D texture which we will call <em>radiance volume</em>. To approximate the incrementing diameter of the cone, and its sampling volume, levels of detail of the voxelized scene are used. For anisotropic voxels six 3D textures at half resolution of the radiance volume are required, one per every axis direction positive and negative, the levels of details are stored within the mipmap levels of these textures which we will call <em>directional volumes</em>.</p>
<p>The radiance volume represents the maximum level of detail for the voxelized scene, this texture is separated from the directional volumes. To bind these two structures, linear interpolation is used between samples of both structures when the mipmap level required for the diameter of the cone ranges between, the maximum level and the first filtered level of detail.</p>
<table class="doxtable">
<tr>
<th>A visualization of the voxel structure  </th></tr>
<tr>
<td align="center"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497571454/DVSGI/voxel_structure_dsmsvc.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md5"></a>
1.2. Dynamic Voxelization</h3>
<p>For dynamic updates, the conservative voxelization of static and dynamic geometry are separated. While static voxelization happens only once, dynamic voxelization happens per frame or when needed. The voxelization for both types of geometry rely on the same process, hence a way to indicate which voxels are static is needed. In my approach I use a single value 3D texture to identify voxels as static, this texture will be called <em>flag volume</em>.</p>
<p>During static voxelization, after a voxel is generated a value is written to the <em>flag volume</em> indicating this position as static. In contrast, during the dynamic voxelization, before generating a voxel, a value is read from the <em>flag volume</em> at the writing position of the voxel, if the value indicates this position is marked as static then writing is discarded, leaving the static voxels untouched.</p>
<p>To constantly revoxelize the scene it is necessary to clear from the 3D textures the previous stored dynamic voxels. This is done before the dynamic voxelization using compute shaders. The <em>flag volume</em> is read to clear voxels under two conditions: if the voxel exists and if it’s dynamic.</p>
<h2><a class="anchor" id="autotoc_md6"></a>
2. Voxel Illumination</h2>
<p>The second step is voxel illumination, for this we calculate the outgoing radiance per voxel using the data stored from the voxelization step. For this we only need the voxel normal, and its position which can be easily extracted by projecting the voxel 3D coordinates in world-space, then we can calculate the direct lighting per voxel. This is all done in a compute shader.</p>
<p>One of the advantages of this technique is that it's compatible with all standard light types like point, spot and directional lights, another is that we don't need shadow maps, though they can help greatly with precision specially for directional lights. Other techniques calculate the voxel radiance per light's shadow map, meaning that for every shadow-mapped light that wants to contribute to the voxel radiance the illumination step has to be repeated.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter"><a class="el" href="class_scene.html" title="Represents a scene composed of many cameras, meshes, lights, textures and materials....">Scene</a> </th><th class="markdownTableHeadCenter">Voxel Direct Lighting  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323827/DVSGI/scene_culelk.png" alt="" style="width: 100%" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497323829/DVSGI/v_direct_vrnajc.png" alt="" style="width: 100%" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md7"></a>
2.1. Normal-Weighted Attenuation</h3>
<p>A disvantage of this technique is the loss of precision averaging all the geometry normals within a voxel. The resulting averaged normal may end up pointing towards a non-convenient direction. This problem is notable when the normal vectors within the space of a voxel are uneven:</p>
<center></center><center><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497413810/DVSGI/uneven_normals_n3klcb.svg" alt="" style="pointer-events: none;" class="inline"/></center><center></center><p>To reduce this issue my proposal utilizes a normal-weighted attenuation, where first the normal attenuation is calculated per every face of the voxel as follows:</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=D_{x,y,z}&space;=&space;(\hat{i}\cdot\Psi,&space;\hat{j}\cdot\Psi,&space;\hat{k}\cdot\Psi)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D_{x,y,z}&space;=&space;(\hat{i}\cdot\Psi,&space;\hat{j}\cdot\Psi,&space;\hat{k}\cdot\Psi)" alt="" title="D_{x,y,z} = (\hat{i}\cdot\Psi, \hat{j}\cdot\Psi, \hat{k}\cdot\Psi)" class="inline"/></a></p>
<p>Then three dominant faces are selected depending on the axes sign of the voxel averaged normal vector:</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=D_{\omega}&space;=&space;\begin{cases}&space;max\{D_{\omega},0\},&space;&amp;&space;N_{\omega}&space;&gt;&space;0&space;\\&space;max\{-D_{\omega},0\},&space;&amp;&space;\text{otherwise}&space;\end{cases}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D_{\omega}&space;=&space;\begin{cases}&space;max\{D_{\omega},0\},&space;&amp;&space;N_{\omega}&space;&gt;&space;0&space;\\&space;max\{-D_{\omega},0\},&space;&amp;&space;\text{otherwise}&space;\end{cases}" alt="" title="D_{\omega} = \begin{cases} max\{D_{\omega},0\}, &amp; N_{\omega} &gt; 0 \\ max\{-D_{\omega},0\}, &amp; \text{otherwise} \end{cases}" class="inline"/></a></p>
<p>And finally, the resulting attenuation is the product of every dominant face normal attenuation, multiplied with the weight per axis of the averaged normal vector of the voxel, the resulting reflectance model is computed as follows:</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=W&space;=&space;N^2\\&space;V_{r}&space;=&space;L_{i}\frac{\rho}{\pi}(W_x&space;D_x&space;&plus;&space;W_y&space;D_y&space;&plus;&space;W_z&space;D_z)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?W&space;=&space;N^2\\&space;V_{r}&space;=&space;L_{i}\frac{\rho}{\pi}(W_x&space;D_x&space;&plus;&space;W_y&space;D_y&space;&plus;&space;W_z&space;D_z)" alt="" title="W = N^2\\ V_{r} = L_{i}\frac{\rho}{\pi}(W_x D_x + W_y D_y + W_z D_z)" class="inline"/></a></p>
<p>where <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;L_i" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;L_i" alt="" title="L_i" class="inline"/></a> is the light source intensity, <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\rho" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\rho" alt="" title="\rho" class="inline"/></a> the voxel albedo, <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;N" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;N" alt="" title="N" class="inline"/></a> the normal vector of the voxel and <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\Psi" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\Psi" alt="" title="\Psi" class="inline"/></a> the light direction.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Normal Attenuation </th><th class="markdownTableHeadNone">Normal-weighted Attenuation  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497414410/DVSGI/shading_standard_e7vzft.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyNone"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497414410/DVSGI/shading_directional_uwyxxw.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md8"></a>
2.2. Voxel Occlusion</h3>
<p>To generate accurate results during the cone tracing step the voxels need to be occluded, otherwise voxelized geometry that is supposed to have little to no outgoing radiance will contribute to the indirect lighting calculations.</p>
<p>The classic shadow mapping or alike techniques can be used to compute the voxels occlusion. The position of the voxel is projected in light space and the depth of the projected point is compared with the stored depth from the shadow map to determine if the voxel is occluded.</p>
<p>My proposal also computes occlusion using raycasting within a volume. Any of the resulting volumes from the voxelization process can be used since the algorithm only needs to determine if a voxel exists at a certain position. To determine occlusion of a voxel, a ray is traced from the position of voxel in the direction of the light, the volume is sampled to determine if at the position of the ray there is a voxel, if this condition is true then the voxel is occluded.</p>
<h4><a class="anchor" id="autotoc_md9"></a>
2.2.1. Soft Voxel Shadows</h4>
<p>Instead of stopping the ray as soon a voxel is found, soft shadows can be approximated with a single ray accumulating a value \<a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\kappa" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\kappa" alt="" title="\kappa" class="inline"/></a> per collision and dividing by the traced distance <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;t" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;t" alt="" title="t" class="inline"/></a>, i.e. <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\nu&space;=&space;\nu&space;&plus;&space;(1&space;-&space;\nu)\kappa\div&space;t" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\nu&space;=&space;\nu&space;&plus;&space;(1&space;-&space;\nu)\kappa\div&space;t" alt="" title="\nu = \nu + (1 - \nu)\kappa\div t" class="inline"/></a>, where <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;1-\nu" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;1-\nu" alt="" title="1-\nu" class="inline"/></a> represents the occlusion value after the accumulation is finished. This technique exploits the observation that, from the light point of view, the number of collisions will usually be higher for the rays that pass through the borders of the voxelized geometry.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Hard Voxel Shadows </th><th class="markdownTableHeadCenter">Soft Voxel Shadows  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497500701/DVSGI/hard_voxel_shadows_ovj32i.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497500702/DVSGI/soft_voxel_shadows_gcmlzm.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497500851/DVSGI/hard_traced_takadd.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497500853/DVSGI/soft_traced_upabyg.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md10"></a>
2.3. Emission</h3>
<p>Adding to the final radiance value the emission term can be used approximate emissive surfaces such as area lights, neon lights, digital screens, etc., this provides a crude approximation of the emission term the rendering equation. After the direct illumination value is obtained the emission term from the voxelization process is added to this value per voxel. During the cone tracing step, these voxels will appear to be bright even on occluded areas, hence indirect light is accumulated per cone from these regions of the voxelized scene.</p>
<h2><a class="anchor" id="autotoc_md11"></a>
3. Anisotropic Voxels</h2>
<p>For more precise results during the cone tracing step anisotropic voxels are used. The mipmapping levels, as seen in the <em>directional volumes</em> in the voxel structure, will store per every voxel six directional values, one per every directional axis positive and negative. Each cone has an origin, aperture angle and direction, this last factor determines which three volumes are sampled. The directional sample is obtained by linearly interpolating the three samples obtained from the selected directional volumes.</p>
<p>To generate the anisotropic voxels I use the process detailed by Crassin <a href="http://maverick.inria.fr/Publications/2011/CNSGE11b/">here</a>. To compute a directional value a step of volumetric integration is done in depth and the directional values are averaged to obtain the resulting value for a certain direction. In my approach this is done using compute shaders, executing a thread per every voxel at the mipmap level that is going to be filtered using the values from the previous level, this process is done per every mipmap level.</p>
<table class="doxtable">
<tr>
<th>Process to generate anisotropic voxels  </th></tr>
<tr>
<td align="center"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497576308/DVSGI/aniso_cropped_aekdhv.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md12"></a>
4. Voxel Cone Tracing</h2>
<p>Voxel cone tracing is similar to ray marching, the cone advances a certain length every step, except that the sampling volume increases along the diameter of the cone. The mipmap levels in the directional volumes are used to approximate the expansion of the sampling volume during the cone trace, to ensure smooth variation between samples quadrilinear interpolation is used which is natively supported with graphics hardware for 3D textures. This step is done in the fragment shader as a screenspace effect, a deferred rendering backend is needed, though voxel cone tracing can be done in forward rendering regardless, it would be extremely inneficient and expensive.</p>
<p>The shape of the cone is meant to exploit the spatial and directional coherence of the many rays packed within the space of a cone. This behavior is used in many approaches such as packet ray-tracing.</p>
<table class="doxtable">
<tr>
<th>Visual representation of a cone used for cone tracing  </th></tr>
<tr>
<td align="center"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497581558/DVSGI/cone_oyxusj.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
</table>
<p>As seen in the figure above each cone is defined by an origin <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;C_o" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;C_o" alt="" title="C_o" class="inline"/></a>, a direction <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;C_d" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;C_d" alt="" title="C_d" class="inline"/></a> and an aperture angle <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\theta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\theta" alt="" title="\theta" class="inline"/></a>. During the cone steps the diameter of the cone is defined by <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;d" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;d" alt="" title="d" class="inline"/></a>, this value can be extracted using the traced distance<a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;t" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;t" alt="" title="t" class="inline"/></a> with the following equation: <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;d=2t\times\tan(\theta\div&space;2)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;d=2t\times\tan(\theta\div&space;2)" alt="" title="d=2t\times\tan(\theta\div 2)" class="inline"/></a>. Which mipmap level should be sampled depending on the diameter of the cone can be obtained using the following equation: <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;V_{level}&space;=&space;log_2(d\div&space;V_{size})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;V_{level}&space;=&space;log_2(d\div&space;V_{size})" alt="" title="V_{level} = log_2(d\div V_{size})" class="inline"/></a>, where <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;V_{size}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;V_{size}" alt="" title="V_{size}" class="inline"/></a> is the size of a voxel at the maximum level of detail.</p>
<p>As described by Crassin <a href="http://maverick.inria.fr/Publications/2011/CNSGE11b/">here</a>, for each cone trace we keep track of the occlusion value <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha" alt="" title="\alpha" class="inline"/></a> and the color value <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;c" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;c" alt="" title="c" class="inline"/></a> which represents the indirect light towards the cone origin <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;C_o" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;C_o" alt="" title="C_o" class="inline"/></a>. In each step we retrieve from the voxel structure the occlusion value <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha_2" alt="" title="\alpha_2" class="inline"/></a> and the outgoing radiance <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;c_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;c_2" alt="" title="c_2" class="inline"/></a>. Then the <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;c" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;c" alt="" title="c" class="inline"/></a> and <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha" alt="" title="\alpha" class="inline"/></a> values are updated using volumetric front-to-back accumulation as follows: <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;c&space;=\alpha&space;c&space;&plus;&space;(1-\alpha)\alpha_2c_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;c&space;=\alpha&space;c&space;&plus;&space;(1-\alpha)\alpha_2c_2" alt="" title="c =\alpha c + (1-\alpha)\alpha_2c_2" class="inline"/></a> and <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha=\alpha&plus;(1-\alpha)\alpha_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha=\alpha&plus;(1-\alpha)\alpha_2" alt="" title="\alpha=\alpha+(1-\alpha)\alpha_2" class="inline"/></a>.</p>
<p>To ensure good integration quality between samples the distance <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;d&#39;" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;d&#39;" alt="" title="d&apos;" class="inline"/></a> between steps is modified by a factor <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\beta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\beta" alt="" title="\beta" class="inline"/></a>. With <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\beta=1" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\beta=1" alt="" title="\beta=1" class="inline"/></a> the value of <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;d&#39;" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;d&#39;" alt="" title="d&apos;" class="inline"/></a> is equivalent to the current diameter <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;d" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;d" alt="" title="d" class="inline"/></a> of the cone, values less than <em>1</em> produce higher quality results but require more samples which reduces the performance.</p>
<h3><a class="anchor" id="autotoc_md13"></a>
4.1. Indirect Illumination</h3>
<p>Indirect lighting is approximated with a crude Monte Carlo approximation. The hemisphere region for the integral in the rendering equation can be partitioned into a sum of integrals. For a regular partition, each partitioned region resembles a cone. For each cone their contribution is approximated using voxel cone tracing, the resulting values are then weighted to obtain the accumulated contribution at the cones origin.</p>
<p>The distribution of the cones matches the shape of the BRDF, for a Blinn-Phong material a few large cones distributed over the normal oriented hemisphere estimate the diffuse reflection, while a single cone in the reflected direction, where its aperture depends on the specular exponent, approximates the specular reflection.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Diffuse Cones </th><th class="markdownTableHeadCenter">Specular Cone </th><th class="markdownTableHeadCenter">BRDF  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497581804/DVSGI/diffuse_cones_oo7hsx.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497581807/DVSGI/specular_cones_faycaz.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497581810/DVSGI/brdf_cones_b4hmdk.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md14"></a>
4.2. Ambient Occlusion</h3>
<p>Ambient occlusion can be approximated using the same cones used for the diffuse reflection for efficiency. For the ambient occlusion term <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\delta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\delta" alt="" title="\delta" class="inline"/></a> we only accumulate the occlusion value <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha_2" alt="" title="\alpha_2" class="inline"/></a>, at each step the accumulated value is multiplied with the weighting function <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;f(r)&space;=&space;\frac{1}{1&plus;\lambda&space;r}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;f(r)&space;=&space;\frac{1}{1&plus;\lambda&space;r}" alt="" title="f(r) = \frac{1}{1+\lambda r}" class="inline"/></a>, where <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;r" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;r" alt="" title="r" class="inline"/></a> is the current radius of the cone and <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\lambda" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\lambda" alt="" title="\lambda" class="inline"/></a> an user defined value which controls how fast <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;f(r)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;f(r)" alt="" title="f(r)" class="inline"/></a> decays along the traced distance. At each cone step the ambient occlusion term is updated as: <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\delta&space;=&space;\delta&space;&plus;&space;(1-\delta)\alpha_2f(r)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\delta&space;=&space;\delta&space;&plus;&space;(1-\delta)\alpha_2f(r)" alt="" title="\delta = \delta + (1-\delta)\alpha_2f(r)" class="inline"/></a>.</p>
<h3><a class="anchor" id="autotoc_md15"></a>
4.3. Soft Shadows</h3>
<p>Cone tracing can also be used to achieve soft shadows tracing a cone from the surface point <em>x</em> towards the direction of the light The cone aperture controls how soft and scattered the resulting shadow is. For soft shadows with cones we only accumulate the occlusion value <a href="https://www.codecogs.com/eqnedit.php?latex=\inline&space;\alpha_2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\inline&space;\alpha_2" alt="" title="\alpha_2" class="inline"/></a> at each step.</p>
<table class="doxtable">
<tr>
<th>Cone Soft Shadows  </th></tr>
<tr>
<td align="center"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497585029/DVSGI/cone_shadow_jwx9pd.svg" alt="" style="pointer-events: none; width: 100%;" class="inline"/>  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md16"></a>
Voxel Global Illumination</h2>
<p>To calculate the diffuse reflection over a surface point using voxel cone tracing we need its normal vector, albedo and the incoming radiance at that point. Since we voxelize the geometry normal vectors and the albedo into 3D textures, all the needed information for the indirect diffuse term is available after calculating the voxel direct illumination. In my approach I perform voxel cone tracing per voxel using compute shaders to calculate the first bounce of indirect diffuse at each voxel. This step is done after the outgoing radiance values from the voxel direct illumination pass are anisotropically filtered.</p>
<p>For each voxel we use its averaged normal vector to generate a set of cones around the normal oriented hemisphere to calculate the indirect diffuse at the position of the voxel. The weighted result from all the cones is then multiplied by the albedo of the voxel and added to the direct illumination value. The resulting outgoing radiance for the radiance volume now stores the direct illumination, and the first bounce of indirect diffuse. The anisotropic filtering process needs be repeated for the new values. This enables us to approximate the second bounce of indirect lighting during the final voxel cone tracing step per pixel. This can be extended to support multiple bounces.</p>
<h1><a class="anchor" id="autotoc_md17"></a>
Results</h1>
<p>The results here were tested on an AMD 380 R9 GPU on different scenes with increasing geometric complexity and dynamic objects added to the scene. The scenes used for testing are listed below:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Name </th><th class="markdownTableHeadCenter">Model </th><th class="markdownTableHeadCenter">Vertices </th><th class="markdownTableHeadCenter">Triangles  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S1 </td><td class="markdownTableBodyCenter"><a href="http://graphics.cs.williams.edu/data/meshes.xml">Cornell Box</a> </td><td class="markdownTableBodyCenter">72 </td><td class="markdownTableBodyCenter">36  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">S2 </td><td class="markdownTableBodyCenter"><a href="http://graphics.cs.williams.edu/data/meshes.xml">Sibenik Cathedral</a> </td><td class="markdownTableBodyCenter">40.479 </td><td class="markdownTableBodyCenter">75.283  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S3 </td><td class="markdownTableBodyCenter"><a href="http://www.crytek.com/cryengine/cryengine3/downloads">Crytek Sponza</a> </td><td class="markdownTableBodyCenter">153.635 </td><td class="markdownTableBodyCenter">278.163  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md18"></a>
Voxelization</h2>
<p>The times per frame for the dynamic and static voxelization of each scene are show below:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Name </th><th class="markdownTableHeadCenter">Static </th><th class="markdownTableHeadCenter">Clear Dynamic </th><th class="markdownTableHeadCenter">Dynamic  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S1 </td><td class="markdownTableBodyCenter">0.51 ms </td><td class="markdownTableBodyCenter">0.78 ms </td><td class="markdownTableBodyCenter">1.30 ms  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">S2 </td><td class="markdownTableBodyCenter">1.80 ms </td><td class="markdownTableBodyCenter">0.58 ms </td><td class="markdownTableBodyCenter">2.11 ms  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S3 </td><td class="markdownTableBodyCenter">11.29 ms </td><td class="markdownTableBodyCenter">0.60 ms </td><td class="markdownTableBodyCenter">2.03 ms  </td></tr>
</table>
<p>For the voxelization process, a higher resolution for the voxel representation can actually be beneficial, because it reduces thread collisions for the writing operations, in the scene S3 there is a higher time for the static voxelization this reason, S3 has a higher triangle density per voxel meaning more syncing operations are needed.</p>
<h2><a class="anchor" id="autotoc_md19"></a>
Voxel Illumination</h2>
<p>The table below shows the results for voxel direct illumination with shadow mapping or raycasting for voxel occlusion and voxel global illumination, it also includes the time for anisotropic filtering after both steps. For voxel direct illumination the times are similar between all scenes using shadow mapping, while raycasting costs more performance it enables occlusion for any type of light source without shadow mapping.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Name </th><th class="markdownTableHeadCenter">Direct (with Shadow Mapping) </th><th class="markdownTableHeadCenter">Direct (with Raycasting) </th><th class="markdownTableHeadCenter">Anistropic Filtering </th><th class="markdownTableHeadCenter">Global Illumination </th><th class="markdownTableHeadCenter">Anistropic Filtering  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S1 </td><td class="markdownTableBodyCenter">1.33 ms </td><td class="markdownTableBodyCenter">20.32 ms </td><td class="markdownTableBodyCenter">1.39 ms </td><td class="markdownTableBodyCenter">8.41 ms </td><td class="markdownTableBodyCenter">1.38 ms  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">S2 </td><td class="markdownTableBodyCenter">0.95 ms </td><td class="markdownTableBodyCenter">4.57 ms </td><td class="markdownTableBodyCenter">1.38 ms </td><td class="markdownTableBodyCenter">3.88 ms </td><td class="markdownTableBodyCenter">1.37 ms  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S3 </td><td class="markdownTableBodyCenter">1.13 ms </td><td class="markdownTableBodyCenter">3.31 ms </td><td class="markdownTableBodyCenter">1.37 ms </td><td class="markdownTableBodyCenter">5.44 ms </td><td class="markdownTableBodyCenter">1.38 ms  </td></tr>
</table>
<p>For raycasting, the amount of empty space in the scene affects how early the traced rays end, which affects the general performance. For high density scenes such as S3 most rays end early, in contrast the scene S1 takes a considerable amount of time using raycasting because the scene is mostly empty space, this same condition also applies for the voxel indirect diffuse step.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter"><a class="el" href="class_scene.html" title="Represents a scene composed of many cameras, meshes, lights, textures and materials....">Scene</a> </th><th class="markdownTableHeadCenter">Voxel Direct </th><th class="markdownTableHeadCenter">Voxel Direct + Indirect Diffuse  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497742010/DVSGI/cornell_scene.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/direct_voxel_cornell.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/gi_voxel_cornell.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497742010/DVSGI/sibenik_scene.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/voxel_direct_sibenik.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/voxel_gi_sibenik.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497742010/DVSGI/sponza_scene.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/voxel_direct_sponza.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497740284/DVSGI/voxel_gi_sponza.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md20"></a>
Voxel Cone Tracing</h2>
<p>Once the voxel structure is anisotropically filtered we can proceed with voxel cone tracing per pixel for the final composition of the image. In my approach six cones with an aperture of 60 degrees are used to approximate the indirect diffuse term, for the indirect specular in these test I utilize a specular cone with an aperture of 10 degrees. The next table shows the performance for indirect lighting on different scenes. For all the scenes my implementation achieves results over 30FPS ( <em><b>&lt; 33.3 ms</b></em> ) under constant dynamic update, meaning objects and lights are changing and moving per frame. The dynamic update includes dynamic voxelization, voxel direct illumination, voxel global illumination and the necessary anistropic filtering steps. For a screen resolution of <em><b>1920x1080</b></em> pixels my implementation obtains an average framerate of <em><b>28.57 ms</b></em> for the scene S3, <em><b>27.02 ms</b></em> for S2 and <em><b>27.77 ms</b></em> for S1 under constant dynamic update, these results show that even with a high resolution the technique can achieve over 30FPS for all the scenes.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter"><a class="el" href="class_scene.html" title="Represents a scene composed of many cameras, meshes, lights, textures and materials....">Scene</a> </th><th class="markdownTableHeadCenter">Direct </th><th class="markdownTableHeadCenter">Indirect (Diffuse + Specular) </th><th class="markdownTableHeadCenter">Direct + Indirect </th><th class="markdownTableHeadCenter">Dynamic Stress  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S1 </td><td class="markdownTableBodyCenter">1.03 ms </td><td class="markdownTableBodyCenter">7.27 ms </td><td class="markdownTableBodyCenter">7.67 ms </td><td class="markdownTableBodyCenter">17.81 ms  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">S2 </td><td class="markdownTableBodyCenter">1.32 ms </td><td class="markdownTableBodyCenter">7.62 ms </td><td class="markdownTableBodyCenter">8.32 ms </td><td class="markdownTableBodyCenter">17.60 ms  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">S3 </td><td class="markdownTableBodyCenter">1.34 ms </td><td class="markdownTableBodyCenter">7.81 ms </td><td class="markdownTableBodyCenter">8.41 ms </td><td class="markdownTableBodyCenter">16.97 ms  </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md21"></a>
Comparison</h2>
<p>Below a visual comparison between a reference image rendered in a path-tracer for 3 hours, another real time global illumination technique called <a href="http://www.crytek.com/download/Light_Propagation_Volumes.pdf">light propagation volumes</a> and my technique. The image generated by my technique is closer to the reference image, specially the indirect diffuse reaching the right columns that aren't directly hit by the light source. <a class="el" href="class_light.html" title="Holds the parameters that describe a scene light source. Supports for three different types of light ...">Light</a> propagation volumes is also limited in the sense that it only provides approximation for the indirect diffuse term, whereas voxel cone tracing achieves specular reflection and many other light phenomena.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Reference (3~ hours) </th><th class="markdownTableHeadCenter"><a href="http://www.crytek.com/download/Light_Propagation_Volumes.pdf">Light Propagation Volumes</a> (18.86 ms) </th><th class="markdownTableHeadCenter">My approach (17.34 ms)  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758681/DVSGI/reference.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758675/DVSGI/lpv_comp.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497758664/DVSGI/sponza_comp.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md22"></a>
Optimizations</h3>
<p>In my implementation the dynamic update can be set to update at a given number of frames or on demand, a simple optimization for example is to update each 5~3 frames, this can easily give results over 60FPS for most scenes with little to zero notable difference.</p>
<p>Since the lighting step is separate from the voxelization step, revoxelization is only truly needed when objects move within the scene. For changes that only involve lighting revoxelization is unnecesary.</p>
<p>One optimization to consider that wasn't implemented in my application is to separate the indirect lighting calculation from voxel cone tracing at a lower resolution. The higher the resolution the more surface points that need to be cone traced since each pixel represents a position in scene. A disvantage of doing this is that it creates some notable artifacts, though they can be somewhat reduced through clever use of screen-space techniques.</p>
<h2><a class="anchor" id="autotoc_md23"></a>
Show Off</h2>
<h3><a class="anchor" id="autotoc_md24"></a>
Dynamic Update</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Cornell Box </th><th class="markdownTableHeadCenter">Sibenik Cathedral </th><th class="markdownTableHeadCenter">Crytek Sponza  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><a href="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/cornell.webm"><img src="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/cornell.jpg" alt="" class="inline"/></a> </td><td class="markdownTableBodyCenter"><a href="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/sibenik.webm"><img src="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/sibenik.jpg" alt="" class="inline"/></a> </td><td class="markdownTableBodyCenter"><a href="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/sponza.webm"><img src="http://res.cloudinary.com/jose-villegas/video/upload/v1497754650/DVSGI/sponza.jpg" alt="" class="inline"/></a>  </td></tr>
</table>
<p>(<em>These are videos</em>)</p>
<h3><a class="anchor" id="autotoc_md25"></a>
Indirect Lighting</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Emissive <a class="el" href="class_material.html" title="Contains parameters that describe a material properties. Its usually bound to a Mesh for rendering.">Material</a> </th><th class="markdownTableHeadCenter">Indirect Shadows  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><a href="http://res.cloudinary.com/jose-villegas/video/upload/v1497757150/DVSGI/emissive.webm"><img src="http://res.cloudinary.com/jose-villegas/video/upload/v1497757150/DVSGI/emissive.jpg" alt="" class="inline"/></a> </td><td class="markdownTableBodyCenter"><a href="http://res.cloudinary.com/jose-villegas/video/upload/v1497757746/DVSGI/indirect_shadows.webm"><img src="http://res.cloudinary.com/jose-villegas/video/upload/v1497757746/DVSGI/indirect_shadows.jpg" alt="" class="inline"/></a>  </td></tr>
</table>
<p>(<em>These are videos</em>)</p>
<h3><a class="anchor" id="autotoc_md26"></a>
Ambient Occlusion</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Cornell Box </th><th class="markdownTableHeadCenter">Sibenik Cathedral </th><th class="markdownTableHeadCenter">Crytek Sponza  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758102/DVSGI/cornell_ao.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758116/DVSGI/sibenik_ao.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758109/DVSGI/sponza_ao.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md27"></a>
Soft Shadows</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">1 degree aperture </th><th class="markdownTableHeadCenter">5 degree aperture </th><th class="markdownTableHeadCenter">10 degree aperture </th><th class="markdownTableHeadCenter">25 degree aperture  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497758213/DVSGI/shadow_1.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497758213/DVSGI/shadow_5.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497758213/DVSGI/shadow_10.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="https://res.cloudinary.com/jose-villegas/image/upload/v1497758213/DVSGI/shadow_25.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md28"></a>
Emissive Materials / Area Lights</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">&#160; </th><th class="markdownTableHeadCenter">&#160;  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758681/DVSGI/area_sponza.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758675/DVSGI/area_shadows.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758681/DVSGI/fine_emissive.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758675/DVSGI/area_teapot.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md29"></a>
Teasers</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">&#160; </th><th class="markdownTableHeadCenter">&#160;  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758681/DVSGI/teaser.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758675/DVSGI/teaser2.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758681/DVSGI/teaser3.png" alt="" style="width: 100%;" class="inline"/> </td><td class="markdownTableBodyCenter"><img src="http://res.cloudinary.com/jose-villegas/image/upload/v1497758675/DVSGI/teaser4.png" alt="" style="width: 100%;" class="inline"/>  </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md30"></a>
Recording</h3>
<p><a href="http://www.youtube.com/watch?v=HwGSoTyP-oM"><img src="https://img.youtube.com/vi/HwGSoTyP-oM/0.jpg" alt="" class="inline"/></a> <a href="http://www.youtube.com/watch?v=52nkpkVZt-g"><img src="https://img.youtube.com/vi/52nkpkVZt-g/0.jpg" alt="" class="inline"/></a> <a href="http://www.youtube.com/watch?v=e1r5VrDtG7k"><img src="https://img.youtube.com/vi/e1r5VrDtG7k/0.jpg" alt="" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md31"></a>
Executable</h1>
<p>The executable application for this technique can be found in this link <a href="https://github.com/jose-villegas/VCTRenderer/releases">here</a> Press Shift + F to enable free camera mode. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.18 </li>
  </ul>
</div>
</body>
</html>
